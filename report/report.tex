\documentclass[twocolumn]{article}
\usepackage{amsmath}
\usepackage{graphicx}

\pagestyle{empty}
\setlength{\textwidth}{7in}
\setlength{\textheight}{9.125in}
\setlength{\columnsep}{0.5in}
\setlength{\topmargin}{-0.8in}
\setlength{\oddsidemargin}{-0.25in}
\setlength{\parindent}{5 ex}

\makeatletter
\def\@normalsize{\@setsize\normalsize{12pt}\xpt\@xpt \abovedisplayskip 11pt
plus2pt minus5pt\belowdisplayskip \abovedisplayskip \abovedisplayshortskip \z@
plus3pt\belowdisplayshortskip 6pt plus3pt
minus3pt\let\@listi\@listI}
%the following line was changed
\def\subsize{\@setsize\subsize{10pt}\xipt\@xipt}
\def\section{\@startsection{section}{1}{\z@}{24pt plus 2 pt
minus 2 pt} {12pt plus 2pt minus 2pt}{\large\bf}}
\def\subsection{\@startsection {subsection}{2}{\z@}{10pt
plus 2pt minus 2pt}{10pt plus 2pt minus 2pt}{\subsize\bf}}
\makeatother

\begin{document}
\date{}
\title{\Large\bf A Distributed Algorithm for 3D Radar Imaging}
\author{\begin{tabular}[t]{c}
Patrick S. Li, Simon Scott \\
Electrical Engineering and Computer Science\\
University of California, Berkeley
\end{tabular}}
\maketitle
\thispagestyle{empty}
\subsection*{\centering Abstract}
\vspace*{-3mm}
\textit{
eWallpaper is a smart wallpaper containing thousands of embedded, low-power processors and radio transceivers. An important application of the wallpaper is to use the radio transceivers to perform 3D imaging using synthetic aperture radar (SAR) techniques. The major obstacles to implementing these techniques on the wallpaper are the distribution of the data amongst the large number of processors, the restrictive 2D mesh topology and the limited local memory on each processor. Our major contribution is a distributed and memory efficient implementation of the 3D imaging algorithm that operates in realtime and achieves video framerates. A hardware simulator was built to allow rapid development and verification of eWallpaper applications. This simulator was parallelized using MPI and Pthreads, enabling fast simulation on a high-performance computing cluster. We developed a performance model and network traffic simulator to verify that our distributed algorithm meets the framerate and memory requirements when running on the actual eWallpaper hardware.
}
\section{Introduction}

eWallpaper is a smart wallpaper with thousands of low-power, RISC-V \cite{riscv} processors embedded within the paper. These processors are connected in a 2D mesh network, spaced 25mm apart. Each processor has its own radio transceiver and antenna.

One of the main objectives of the eWallpaper is to use the radio transceivers to image the room. The radios attached to each of the processors transmit millimeter-wave pulses. These pulses reflect off the objects in the room and the echoes are recorded back at the antennas. The echoes are combined using techniques borrowed from synthetic aperture radar to form a single three-dimensional image of the room.

\subsection{Applications of the eWallpaper Imaging System}

While being able to use wallpaper to form 3D images of a room is interesting, basic imaging is not the final goal of the eWallpaper. It is instead a technology that enables other high-level functions possible, such as:

\begin{itemize}
\item Gesture recognition, allowing people to control the automated functions and multimedia in their homes.
\item Monitoring of human vital signs and requesting medical assistance when, for example, a person is immobile on the floor.
\item Tracking of persons without the house for security purposes. Gurbuz et al \cite{human-recognition} describe a technique for identifying people using radar signals.
\item Creation of immersive audio fields for teleconferencing \cite{immersive-audio} that follow people as they walk around
\end{itemize}

\subsection{Challenges with Performing Realtime Imaging}

The proposed design for a single sheet of eWallpaper consists of an array of 128 x 128 antennas and processors, with each processor storing 256 echoes. These echoes are then  combined to form a three-dimensional image of room using the 3D Range Migration Algorithm \cite{3d-imaging-concealed-weapon}, which has been adapted from synthetic aperture radar (SAR) techniques. There are three key challenges to implementing this algorithm on eWallpaper:
\begin{enumerate}
\item The recorded antenna responses are distributed amongst the 128 x 128 processors. This means that the algorithm must too be distributed.
\item Moving data between processors can be expensive, due to the low-dimensional network topology (2D mesh).
\item The amount of available memory on each processor is extremely limited, on the order of 100KB. Furthermore, there is no global memory storage. This means that the echoes cannot all be sent to a single processor for computation.
\end{enumerate}

Taking these limitations into account, we developed a distributed implementation of the 3D range migration algorithm that is both memory efficient and able to achieve video framerates.

\section{The 3D Range Migration Algorithm}
\label{algorithm-section}

The algorithm we adapted for performing 3D range migration is identical to the one presented in [] for 3D imaging using millimeter waves. The input to the algorithm is a 3D array of amplitudes and phase offsets recorded by the radio transceivers which is used to compute the reflectivity of every point in the scene. 

During the scanning procedure, a single radio antenna will emit a continuous sinusoidal wave. The wave will reflect off of the objects in the room and is received by a radio transceiver located beside the transmitting antenna. The amplitude of the received sin wave and the phase offset between the transmitted and received wave are recorded. This procedure is repeated over a range of evenly spaced frequencies and for each antenna in turn. In our setup, we have 128$\times$128 antennas, each of which scan through 256 frequencies, thus the input to the imaging algorithm is 128$\times$128$\times$256 amplitudes and phase offsets.

We will assume, in the development of the algorithm, that the speed of light is known and constant for all points in the scene, i.e. that there is negligible difference between the speed of light in human tissue and in air. We also do not consider any diffraction, refraction, or attenuation effects. We will model the scene as a collection of discrete point targets distributed uniformly throughout the region to be imaged. Each point target, at position $(x,y,z)$, is fully described by a single coefficient, $0 \leq r \leq 1$, which represents its reflectivity. The sin wave emitted by a radio antenna is assumed to travel, unimpeded, to all points in the scene. They reflect off the targets and arrive back at the radio transceiver with amplitude $r$. The superposition of the reflected waves from each target is recorded by the radio transceiver. This physical model is minimal but is sufficient for the purposes of imaging.

Formally, consider a single antenna at position $(x', y', 0)$. Let $d = \sqrt{(x'-x)^2+(y'-y)^2+z^2}$ be the distance from the antenna to a target at position $(x,y,z)$. The time it takes for the sin wave emitted by the antenna to travel to the target and back again is $t = \frac{2d}{c}$, where $c$ is the speed of light. In that time, the phase of the transmitted sin wave has advanced by $\phi = \omega t$, where $\omega$ is the angular frequency of the sin wave. The sin wave received by the transceiver can be represented as a single complex number, $r e^{-j \phi}$, where the amplitude of the wave is represented by the magnitude, and the phase offset is represented by the angle. Thus, the final received signal at the transceiver, from the superposition of the reflected waves from each point target, is given by
%
\begin{gather}
s(x', y', z=0, \omega) = \int \int \int r(x,y,z) e^{j \phi(x,y,z)} dx dy dz \nonumber \\
= \int \int \int r(x,y,z) e^{j \frac{2}{c} \sqrt{(x'-x)^2 + (y'-y)^2 + z^2}} dx dy dz.
\end{gather}

The received signal has, thus far, been described as the superposition of the reflections from each point target of a sin wave originally emitted by the antenna. Alternatively, we can equivalently interpret the point targets to be, themselves, emitting sin waves which travel at half the speed of light, $\frac{c}{2}$, to arrive at the transceiver. Under this interpretation, the scene generates a wavefield, $s(x,y,z,\omega)$, and the transceivers sample the wavefield on the plane $z=0$ to obtain $s(x,y,z=0,\omega)$. Our goal is to recover the full wavefield, $s(x,y,z,\omega)$ given only $s(x,y,z=0,\omega)$.

The wavefield at depth $z$ can be recovered by back propagating the recorded wavefield, $s(x, y, z=0, \omega)$, from the antenna to the target. This can be achieved by simply swapping the sign of the phase delay term, which represents propagation backwards in time, and summing over the contribution from each antenna.
%
\begin{gather}
s(x,y,z,\omega) =\int\int s(x',y',z=0,\omega) \nonumber \\
e^{-j \omega \frac{2}{c} \sqrt{(x'-x)^{2}+(y'-y)^{2}+z^{2}}} dx'dy'.
\end{gather}
%
After backwards propagation, the final 3D image can be reconstructed by integrating the wavefield over all frequencies.
\begin{equation}
s(x,y,z)=\int s(x,y,z,\omega) d\omega.
\end{equation}

While the above algorithm is intuitive, the need to integrate over all frequencies and antenna positions for each scene position makes computation prohibitively expensive. For 128$\times$128 antennas and 256 frequencies, it took over two and a half hours on a 24 node cluster to image a room. To make computation tractable, we pre-transform our received signal to the frequency domain, where we will do all our computations, and then transform back to the spatial domain.

Let $S(k_x,k_y,z=0,\omega) = \text{FT}_{x,y} \{ s(x, y, z=0, \omega) \}$ be the Fourier transform of the recorded wavefield with respect to $x$ and $y$. Back propagation becomes an efficient element-wise multiplication in the frequency domain.
\begin{equation}
	S(k_x, k_y, z, \omega) = S(k_x, k_y, z=0, \omega) e^{-j k_z z},
\end{equation}
where
\begin{equation}
  	k_z = \sqrt{ (\frac{2 \omega}{c}) ^ 2 - k_x^2 - k_y^2}.
\end{equation}

The image in the frequency domain is reconstructed, as before, by integrating the back propagated field over all frequencies.
\begin{equation}
	S(k_x, k_y, z) = \int S(k_x, k_y, z=0, \omega) e^{-j k_z z} d\omega. \label{eq:stolt-integral}
\end{equation}
Finally, we use the inverse Fourier transform to recover the image in the spatial domain, $s(x,y,z) = \text{IFT}_{k_x, k_y} \{ S(k_x, k_y, z) \}$. 

The pre and post Fourier transforms can be done efficiently using FFTs, and back propagation is a fast element-wise multiplication in the frequency domain. The only remaining integral at this point is given by equation \ref{eq:stolt-integral}, which as a further optimization, can be computed efficiently by noting that it has a similar form to the inverse Fourier transform. 

By resampling $S(k_x, k_y, z=0, \omega)$ at evenly spaced intervals of $k_z$ (a technique known as Stolt interpolation in the seismic imaging field),
\begin{equation}
	S'(k_x, k_y, z=0, k_z) = \text{Stolt}\{ S(k_x, k_y, z=0, \omega) \},
\end{equation}
the integral in equation \ref{eq:stolt-integral} can be efficiently computed using an inverse FFT. Resampling may be done using linear interpolation.
\begin{gather}
	S(k_x, k_y, z) = \int S(k_x, k_y, z=0, \omega) e^{-j k_z z} d\omega 	\nonumber \\
	= \int S'(k_x, k_y, z=0, k_z) e^{-j k_z z} dk_z	\nonumber \\
	= \text{IFT}_{k_z} \{ S'(k_x, k_y, z=0, k_z) e^{-j k_z z_0} \},
\end{gather}
where $z_0$ is the minimum distance from the antenna plane that we wish to image.

The whole algorithm is then given as follows:
1. Pre-transform the received signal to the frequency domain using a FFT.
\begin{equation}
	S(k_x,k_y,z=0,\omega) = \text{FT}_{x,y} \{ s(x, y, z=0, \omega) \}.
\end{equation}
2. Perform back propagation and image reconstruction in the frequency domain, using Stolt interpolation.
\begin{gather}
	S(k_x, k_y, z) = 	\nonumber \\
	\text{IFT}_{k_z} \{ \text{Stolt}\{ S(k_x, k_y, z=0, \omega) \} e^{-j k_z z_0} \}.
\end{gather}
3. Transform the reconstructed image back to the spatial domain using an IFFT.
\begin{equation}
	s(x, y, z) = \text{IFT}_{k_x, k_y} \{ S(k_x, k_y, z) \}.
\end{equation}
The reconstructed image, $s(x,y,z)$, is a 3D array whose values represent the reflectivity at each point the room.

\section{Implementation on a 2D Mesh Network}

A single sheet of eWallpaper contains 16384 low-power Rocket processors, arranged in a 128 x 128 array. Since the wires between processors are printed using conductive inks, only nearest-neighbor connections can be formed. This results in a 2D mesh network of bi-directional links.

The Rocket processor is based on the RISC-V \cite{riscv} ISA. It has a 6-stage, in-order pipeline, running at 1GHz. It also has an additional floating-point unit, capable of approximately 200 MFlops/s. Each processor has a 64KB L1 cache and 100KB of on-chip main memory. There is therefore no DRAM and no off-processor memory in the eWallpaper.

In order to implement the imaging algorithm described in Section~\ref{algorithm-section} on the eWallpaper, two important operations need to be defined: the row-wise transpose and the column-wise transpose.

\subsection{The Row-wise Transpose}

Assuming there are P processors in a row in the mesh network, each containing N data values, the values stored on a single processor $q$ can be expressed as:
\[ D_q = \{d_{q1}, d_{q2}, d_{q3}, ..., d_{qN}\} \]
After performing the row-wise transpose, the values stored on processor $q$ are:
\[ D_q = \{d_{1q}, d_{2q}, d_{3q}, ..., d_{Nq}\} \]
Therefore, after the transpose, the $q^{th}$ processor in the row contains the $q^{th}$ value stored by all the processors before the transpose.

The 3D matrix on the left of Figure~\ref{row_wise_transpose} represents a 3x3 processor array, with each processor storing the magnitude and phase values for 3 frequencies(represented by the 3 circles at each processor). In order to perform a row-wise transpose, each processor first sends its locally stored data to its left and right neighbors. Once the transmission has completed, each processor receives a complete packet from its left neighbor. It extracts the required value from this packet (the $q^{th}$ processor extracts the $q^{th}$ value from the packet) and forwards the packet to the right neighbor. Similarly, it receives and packet from its right neighbor, extracts a value, and forwards the packet to the left neighbor. In this way, a full row-wise transpose can be performed in $P-1$ hops for a row of $P$ processors.

\begin{figure}[!h]
\centering
\includegraphics*[width=0.5\textwidth, viewport = 10 10 620 150]{figures/row_wise_transpose.pdf}
\caption{A 3x3 processor array, before and after the row-wise transpose}
\label{row_wise_transpose}
\end{figure}

The 3D matrix on the right of Figure~\ref{row_wise_transpose} shows the data stored in each processor after the transpose. The processors in the first column store the first frequency values, the processors in the second column the second frequency values, etc. Note that during the row-wise transpose operation, only processors in the same row communicate. This allows all rows to be transposed at the same time.

This is very similar to the Ring Exchange Algorithm described by Christara et al \cite{efficient-transposition} for ring networks. Christara et al argue that store and forward is better than wormhole routing for the transposition operation on a ring network, as each processor requires data from all other processors. Furthermore, they prove that this approach is optimal for a ring network, as it performs the transpose in $P-1$ hops.

The one difference between the Ring Exchange Algorithm and our row-wise transpose is that the processors, in our approach, forward the entire packet after extracting the required values, while the processors in the Ring Exchange Algorithm only forward the values that they do not require. The result is that our approach incurs twice the total bandwidth cost as the Ring Exchange Algorithm.

\subsection{The Column-wise Transpose}

The column-wise transpose, shown in Figure~\ref{column_wise_transpose}, works in the same way as the row-wise transpose, except that processors in the same column communicate.

\begin{figure}[!h]
\centering
\includegraphics*[width=0.5\textwidth, viewport = 40 10 650 150]{figures/column_wise_transpose.pdf}
\caption{A 3x3 processor array, before and after the column-wise transpose}
\label{column_wise_transpose}
\end{figure}

\subsection{The Distributed 3D Imaging Algorithm}

With the row-wise and column-wise transpose operations defined, the imaging algorithm described in Section~\ref{algorithm-section} can be defined as a sequence of computation and communication steps, as in Figure~\ref{algorithm_labeled}. These operations are performed concurrently, but not necessarily in synchronization, on all processors in the network. The yellow boxes in the diagram represent computational operations, while the grey boxes represent communication.

\begin{figure}[!h]
\centering
\includegraphics*[width=0.3\textwidth, viewport=10 70 430 750]{figures/algorithm_labeled.pdf}
\caption{The distributed 3D range migration algorithm that runs on each processor}
\label{algorithm_labeled}
\end{figure}

The 2D FFT across the entire dataset, with respect to $x$ and $y$, is computed as a set of 1D FFTs along the $x$-axis, followed by a set of 1D FFTs along the $y$-axis. At the start of the algorithm, each processor contains the echoes that were recorded at its own antenna, for each of the 256 frequency steps. A row-wise transpose is performed, with the result being that each processor contains the echoes at all 128 $x$ positions for just two frequencies. The processor then performs two 128-point 1D FFTs on the locally stored data. This is followed by a column-wise transpose, so that each processor now contains the echo data at all 128 $y$ positions, for a particular $kx$ value and just two frequencies. Finally, each processor once again performs two 128-point 1D FFTs on locally stored data, completing the 2D FFT.

After the 2D FFT, a row-wise transpose is performed, with the result being that each processor contains all 256 frequency values for a particular $kx$ and $ky$. The processor is now able to perform a backward propagation and Stolt interpolation on locally stored data, without needing to communicate with any other processors. The backward propagation involves multiplying each stored value by a unique complex number. Stolt interpolation is achieved using linear interpolation. Both the back propagation coefficients and the linear interpolation indices are precomputed to accelerate computation.

The final 3D inverse FFT is implemented using three separate 1D IFFTs with interleaving row and column transposes. At the end of the algorithm, each processor contains the reflectivity at all 256 depths ($z$-values) at a particular $(x,y)$ position.

\section{High Performance Functional Simulator}

To aid the development of the imaging algorithm, we created a functional simulator for fast prototyping and debugging of eWallpaper applications. eWallpaper applications are written in Single Program Multiple Data (SPMD) style, and one program instance is launched per simulated processor. Each processor knows its own coordinates on the eWallpaper processor grid, and has access to a set of minimal communication functions for sending and receiving data packets from its immediate neighbors. The simulator was parallelized to run efficiently on an MPI cluster. Within a MPI node, multiple virtual processors are simulated using Pthreads. 

The following basic functions are provided for interprocessor communication:
\begin{itemize}
	\item \textbf{send\_message(direction, message, message\_size)} sends a message with the provided message size to one of the four neighboring processors.
	\item \textbf{receive\_message(direction)} receives a message from one of the four neighboring processors. A pointer to the start of the message buffer is returned.
	\item \textbf{set\_receive\_message(direction, buffer)} instructs the network router to place incoming packets in the provided buffer.
\end{itemize}

{\em send\_message} blocks until the network router is free to send and the receiving processor has space available to hold the message. Note that {\em send\_message} returns as soon as message transmission begins, {\em not} when message transmission is completed. {\em receive\_message} blocks until there is a message waiting in the network buffer. Within a single MPI node, network functions are simulated using shared memory and mutexes. Across MPI node boundaries, network functions are implemented on top of MPI Isend and Irecv operations. These MPI node boundaries are invisible to the eWallpaper application.

For computationally intensive applications, the simulator can be configured to run on more MPI nodes, with a smaller number of virtual processors being simulated on each node. For faster prototyping and debugging, we can use less MPI nodes by increasing the number of simulated virtual processors per node. In the limit, we can configure the simulator to simulate {\em all} the virtual processors on a single node allowing the entire simulation to be run on a single local machine. This feature was of great benefit to us during the development phase of the algorithm, allowing a much shorter edit-test-debug cycle by circumventing the lengthy job-queue system on Nersc. 

\section{Simulated Imaging Results}

Our distributed algorithm was tested on our functional simulator running on a 64 core cluster. Antenna responses are artificially generated from an input test scene. Figure [] shows an input scene consisting of three points of varying reflectivities, the top-left point being least reflective and the bottom-right point being most reflective. Figure [] shows the reconstructed image output by our algorithm. The brightest object in the recovered image corresponds to the point with highest reflectivity. 

Figure [] shows an input scene consisting of a collection of points distributed along the surface of a sphere, and the reconstructed image is shown in Figure []. The input data for the recovered images shown in Figure [] and [] was generated from a CT scan of human head from the Stanford dataset. The recovered head is shown from two different angles.

\section{Investigation of Design Parameters}

Simon was HERE!!!
 
- communication patterns
- bandwidth
- array size (resolution)
- amount of precomputation
Observe:
- framerate
- cpu load
- memory

1. For this, you need a timing model. you need a traffic simulator.
2. We investigate (vary bandwidth, vary comuication, vary ..)
-- describe different communication patterns

\begin{figure}[!h]
\centering
\includegraphics*[width=0.4\textwidth, viewport=80 10 700 590]{figures/comm_patterns_arrows.pdf}
\caption{Possible communication patterns for the imaging algorithm}
\label{comm_patterns_arrows}
\end{figure}

\section{Performance Results}
3. Show the trends vs. parameters

\section{Related Work}

The ?experimental setup? for performing imaging using a 2D array of transceivers originated in the field of seismic data processing. Controlled explosions, and later frequency-swept oscillators, were used to emit a pulse from the surface of the earth. The reflected pulses were recorded, and detailed images of the subterranean structures were formed. Techniques for improving computational efficiency, such as range migration, were also first introduced in this field.

Since then, range migration has been extended and adapted to many imaging fields such as synthetic aperture radar (SAR) by Cafforio et al. [], microwave holography [], and, most recently, 3D imaging using millimeter-wave technology on which this work is based. In place of a 2D array of antennas, their system uses a scanned linear array of antennas and forms images at the rate of 1-2s per frame. Our achieved framerates of 75 frames per second are due to the combination of electronically switched 2D array of antennas, and a fully distributed algorithm running on a massively parallel system. 

- Three-Dimensional Millimeter-Wave Imaging for Concealed Weapon Detection
- 3-D Radar Imaging Using Range Migration Techniques
- SAR Data Focusing Using Seismic Migration Techniques
- Mention that one group accelerated a version of the 2D algorithm using GPUs. Not 3D though.

- concealed weapons
- original SAR paper
- near-field 3D SAR imaging
- realtime through-wall imaging
- FFT's on ring topologies
- Matrix transpose on 1D array using systolic arrays \cite{systolic-arrays-transpose}

- Applications: heart rate monitoring for Olympics

\section{Conclusion}
- Conclude.

- Future Work.
 - Build HW prototype
 - Make row/column transpose twice as fast
 - Investigate more efficient 2D and 3D FFTs

\subsection*{Acknowledgements}
SWARM lab?
Kurt?


{\small
\bibliographystyle{IEEEtran}
\bibliography{bib}
}

\end{document}
